{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a6cd3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d450c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('bonus-exercises').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a6408",
   "metadata": {},
   "source": [
    "1. Read movies csv as a py-spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1be95d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('csv/movies.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9da0d876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- rank: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eca06ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----+----+\n",
      "|  id|                name|year|rank|\n",
      "+----+--------------------+----+----+\n",
      "|  70|       'Brennus', Le|1897|NULL|\n",
      "| 460|  ...und Du bist die|1992|NULL|\n",
      "| 477|...und sowas nenn...|1971|NULL|\n",
      "| 838|1001 Posies do Am...|1979|NULL|\n",
      "|1007| 120, rue de la Gare|1946|NULL|\n",
      "|1087|    13th Letter, The|1951| 5.8|\n",
      "|1269|     18 and Nasty 34|2003|NULL|\n",
      "|1313|18/68: Venecia ka...|1968|NULL|\n",
      "|1327|                1818|1997|NULL|\n",
      "|1449|1995 MTV Movie Aw...|1995|NULL|\n",
      "+----+--------------------+----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(0.01).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9aa3aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix data types\n",
    "df = df.withColumn(\"year\", col(\"year\").cast(\"int\"))\n",
    "df = df.withColumn(\"rank\", col(\"rank\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "44640104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- rank: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "20a704ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388269"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04df79",
   "metadata": {},
   "source": [
    "2. Groupby dataframe by year to show number of movies per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "48c034c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupBy('year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "035aa2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|1959| 2839|\n",
      "|1990| 5949|\n",
      "|1896|  410|\n",
      "|1903|  831|\n",
      "|1975| 4269|\n",
      "|1977| 3905|\n",
      "|1924| 1847|\n",
      "|2003|11606|\n",
      "|2007|    7|\n",
      "|1892|    9|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a94df",
   "metadata": {},
   "source": [
    "3. Short the grouped dataframe on year asc and desc. Do you see anything suspicious?  \n",
    "Dataframe probably contains malformed/corrupted data. Py-spark provides you appropriate options to handle similar situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10af1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|NULL| 7210|\n",
      "|   0|    1|\n",
      "|   2|    4|\n",
      "|1888|    2|\n",
      "|1890|    3|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped.sort(col('year').asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d5de7aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2008|    1|\n",
      "|2007|    7|\n",
      "|2006|  194|\n",
      "|2005| 1433|\n",
      "|2004| 8521|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped.sort(col('year').desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32cc9e",
   "metadata": {},
   "source": [
    "The dataset does not intend to have the year field as nullable yet we are seeing many lines due to unescaped commas mostly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348eadf2",
   "metadata": {},
   "source": [
    "4. Could you read again df_movies in a way that enables you separate good from corrupted lines and store those corrupted lines in another dataframe?  \n",
    "Try again the groupby+sort step with the clear dataset. Better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f2fd9a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, name: string, year: int, rank: float, _corrupt_record: string]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"year\", IntegerType(), False),\n",
    "    StructField(\"rank\", FloatType(), True),\n",
    "    StructField(\"_corrupt_record\", StringType(), True)  \n",
    "])\n",
    "\n",
    "# Read with permissive mode and corrupt record tracking\n",
    "df_movies = spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .csv(\"csv/movies.csv\", header=True)\n",
    "\n",
    "# necessary step, otherwise all _corrupt_record data is lost, as it does not exist in the original csv\n",
    "df_movies.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8c67e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388269"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f357c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_good = df_movies.filter(\"_corrupt_record IS NULL\")\n",
    "df_movies_bad = df_movies.filter(\"_corrupt_record IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29972f83",
   "metadata": {},
   "source": [
    "After capturing corrupted values we can see that the non-corrupted rows contain only acceptable values for the 'year' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dcec75fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|1888|    2|\n",
      "|1890|    3|\n",
      "|1891|    6|\n",
      "|1892|    9|\n",
      "|1893|    2|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies_good.groupBy(\"year\").count().sort(col('year')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f461b25",
   "metadata": {},
   "source": [
    "And the corrupted dataframe contains only the invalid year and nothing else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a80f19a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|NULL| 7214|\n",
      "|   0|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies_bad.groupBy(\"year\").count().sort(col('year')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "736d7b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381054"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies_good.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6582a229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7215"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies_bad.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ac8e0",
   "metadata": {},
   "source": [
    "Not part of the exercises but let's try to retrieve the missing years from the corrupt columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f4382a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"year\", IntegerType(), False),\n",
    "    StructField(\"rank\", FloatType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526fadd",
   "metadata": {},
   "source": [
    "In the name field there are single and triple quotes. Assigning '\"' as both an escape and a quote character, is not perfect, but will do the trick of recovering dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "252bbe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"quote\", \"\\\"\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"csv/movies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92aa087d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388269"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a9a9ab09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|282455|Roundhay Garden S...|1888|NULL|\n",
      "|337409|Traffic Crossing ...|1888|NULL|\n",
      "|218186| Monkeyshines, No. 1|1890| 7.3|\n",
      "|218187| Monkeyshines, No. 2|1890|NULL|\n",
      "|218188| Monkeyshines, No. 3|1890|NULL|\n",
      "+------+--------------------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(col(\"year\").asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c97193fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----+----+\n",
      "|    id|                name|year|rank|\n",
      "+------+--------------------+----+----+\n",
      "|139653|Harry Potter and ...|2008|NULL|\n",
      "|272424|  Rapunzel Unbraided|2007|NULL|\n",
      "| 92850|        DragonBall Z|2007|NULL|\n",
      "|311040|        Spider-Man 3|2007|NULL|\n",
      "|139654|Harry Potter and ...|2007|NULL|\n",
      "+------+--------------------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(col(\"year\").desc()).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
